{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "90752534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "61ba6262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "f = open(\"TVs-all-merged.json\")\n",
    "data = json.load(f)\n",
    "\n",
    "# This function loops over the dictionary and the key value pairs\n",
    "def pairs_dict(dict_object):\n",
    "    for key, value in dict_object.items():\n",
    "        if isinstance(value, dict):\n",
    "            for product in pairs_dict(value):\n",
    "                yield (key, *product)\n",
    "        else:\n",
    "            yield (key, value)\n",
    "\n",
    "\n",
    "# Extracts the title of every product\n",
    "counts = {}\n",
    "All_titles = []\n",
    "validation_df = pd.DataFrame(columns=['model ID', 'title'])\n",
    "for pair in pairs_dict(data):\n",
    "    for item in range(len(pair[1])):\n",
    "        title = pair[1][item]['title']\n",
    "\n",
    "        # Remove modelIDs from titles\n",
    "        model_id = pair[0]\n",
    "        if model_id in title:\n",
    "            title = title.replace(model_id, '')\n",
    "\n",
    "        # Remove al non-alphanumeric characters and standardize words\n",
    "        title = re.sub('(/ |- |Newegg.com| TheNerds.net|Best Buy|,|\\+|:|\\)|\\(| tv| TV|Class|;|*|$| )', '', title)\n",
    "        title = re.sub('(-inch|inch|\"|Inch|inches| inch| Inch|-Inch)', 'inch', title)\n",
    "        title = re.sub('(Hz|hz|Hertz|hertz|HZ| hz|-hz| Hz)', 'hz', title)\n",
    "\n",
    "        # Count the number of words in the titles\n",
    "        for word in title.split():\n",
    "            word = word.lower()\n",
    "            if word in counts:\n",
    "                counts[word] += 1\n",
    "            else:\n",
    "                counts[word] = 1\n",
    "        All_titles.append(title.lower())\n",
    "\n",
    "        validation_df = validation_df.append({'model ID': model_id, 'title': title}, ignore_index=True)\n",
    "        \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5469759e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n"
     ]
    }
   ],
   "source": [
    "duplicates_number = 0\n",
    "valuecount = validation_df['model ID'].value_counts()\n",
    "for modelcount in valuecount:\n",
    "    if modelcount == 2:\n",
    "        duplicate_pairs += 1\n",
    "    elif modelcount == 3:\n",
    "        duplicate_pairs += 3\n",
    "    elif modelcount == 4:\n",
    "        duplicate_pairs += 6\n",
    "    else:\n",
    "        continue\n",
    "print(duplicates_number)\n",
    "\n",
    "# Sort counts and create a new dictionary with words that only appear once\n",
    "wordcounts_one = {k: v for k, v in counts.items() if v == 1}\n",
    "wordcounts = {k: v for k, v in counts.items() if v != 1}\n",
    "\n",
    "# Remove words with single appearance\n",
    "titles_final = []\n",
    "for title in titles:\n",
    "    for word1 in wordcounts_one.keys():\n",
    "        if word1 in title.split():\n",
    "            title = title.replace(word1, '')\n",
    "    titles_final.append(title)\n",
    "\n",
    "# data cleaning, removing the spaces at beginning and end\n",
    "count = 0\n",
    "for title in titles_final:\n",
    "    if title.startswith(' '):\n",
    "        title = title[1:]\n",
    "    if title.startswith(' '):\n",
    "        title = title[1:]\n",
    "    if title.endswith(' '):\n",
    "        title = title[:-1]\n",
    "    if title.endswith(' '):\n",
    "        title = title[:-1]\n",
    "    titles_final[count] = title\n",
    "    count += 1\n",
    "\n",
    "# seperating each word and putting in seperate list\n",
    "titles_split = []\n",
    "for title in titles_final:\n",
    "    titles_split.append(title.split())\n",
    "\n",
    "# Make Boolean Matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "df = pd.DataFrame({\"titles\": titles_split})\n",
    "df = pd.DataFrame(mlb.fit_transform(df['titles']), columns=mlb.classes_, index=df.index)\n",
    "df = df.transpose()\n",
    "deleted_titles = df.loc[:, (df == 0).all(axis=0)]\n",
    "df = df.loc[:, (df != 0).any(axis=0)]\n",
    "df = df.transpose()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df = df.transpose()\n",
    "for title in deleted_titles:\n",
    "    validation_df = validation_df[validation_df.index != title]\n",
    "validation_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "634153b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            model ID                                              title\n",
      "0       29PFL4508/F7  Philips 4000 Series 29inch 2812inch Diag. LED ...\n",
      "1            SC-3211                   SuperSonic 32inch 720p LED HDTV \n",
      "2        LC-90LE657U  Sharp AQUOS 90inch 90inch Diag. LED 1080p 120h...\n",
      "3       39PFL2908/F7  Philips 2000 Series 39inch 3858inch Diag. LED ...\n",
      "4         LC70LE550U   Sharp Aquos 70inch 69.5inch Diagonal 1080p 12...\n",
      "...              ...                                                ...\n",
      "1619      TC-P55GT31  Panasonic VIERA 55inch  Plasma 1080p 600hz 3D ...\n",
      "1620  UN40EH5000FXZA  Samsung 40inch 40inch Diag. LED 1080p 60hz HDTV  \n",
      "1621  UN40EH5000FXZA  Samsung 40inch 40.0inch Diag. 1080p 60hz LED H...\n",
      "1622    NS-32E859A11    Insignia Connected 32inch 1080p 120hz LED HDTV\n",
      "1623            E424  NEC 42inch 42inch Diag. LEDLCD 1080p HDTV 1080p  \n",
      "\n",
      "[1624 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for model_id in \n",
    "    if validation_df[model_id] == \n",
    "print(validation_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f569336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_list(lst_1, lst_2):\n",
    "    list_intersection = [value for value in range(len(lst_1)) if lst_2[value] == 1 and lst_1[value] == 1]\n",
    "    return list_intersection\n",
    "\n",
    "\n",
    "def union_list(lst_1, lst_2):\n",
    "    try:\n",
    "        list_union = lst_1.value_counts()[1] + lst_2.value_counts()[1] - len(intersection_list(lst_1, lst_2))\n",
    "    except:\n",
    "        print(lst_1.value_counts())\n",
    "        print(lst_2.value_counts())\n",
    "        print(lst_1.value_counts()[1])\n",
    "        print(lst_2.value_counts()[1])\n",
    "    return list_union\n",
    "\n",
    "\n",
    "def jaccardSim(d1, d2):\n",
    "    return len(intersection_list(d1, d2)) / union_list(d1, d2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "788ad65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 337/337 [02:25<00:00,  2.31it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-1aaa52befab4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mband\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbands\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mband_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mband\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mhashbuckets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mband_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mcandidate_pairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "signature_matrix = np.full((len(df.columns), 150), np.inf)\n",
    "hash_functions = []\n",
    "#Set seed\n",
    "random.seed(123)\n",
    "# generate the signature matrix using minhashing\n",
    "for row in tqdm(range(len(df))):\n",
    "    hash_row = []\n",
    "    for i in range(150):\n",
    "        np.random.seed(1)\n",
    "        int1 = random.randint(0, 100)\n",
    "        np.random.seed(2)\n",
    "        int2 = random.randint(0, 100)\n",
    "        hash_value = (int1 + int2 * (row + 1)) % 887\n",
    "        hash_row.append(hash_value)\n",
    "    hash_functions.append(hash_row)\n",
    "    for column in df.columns:\n",
    "        if (df.iloc[row][column] == 1):\n",
    "            for i in range(len(hash_functions[row])):\n",
    "                value = hash_functions[row][i]\n",
    "                if value < signature_matrix[column][i]:\n",
    "                    signature_matrix[column][i] = value\n",
    "signmatrix = signature_matrix.transpose()\n",
    "\n",
    "\n",
    "# Perform Locality Sensitive Hashing algporithm\n",
    "b=30\n",
    "r=5\n",
    "n, d = signmatrix.shape\n",
    "assert(n==b*r)\n",
    "hash_buckets = collections.defaultdict(set)\n",
    "bands = np.array_split(signmatrix, b, axis=0)\n",
    "for k,band in enumerate(bands):\n",
    "    for j in range(d):\n",
    "        band_id = tuple(list(band[:,j])+[str(k)])\n",
    "        hash_buckets[band_id].add(j)\n",
    "candidate_pairs = set()\n",
    "for bucket in hash_buckets.values():\n",
    "    if len(bucket) > 1:\n",
    "        for pair in itertools.combinations(bucket, 2):\n",
    "            candidate_pairs.add(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "29c6eaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9723\n",
      "28\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-d212019146fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mfound_duplicates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'duplicate label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mnumber_of_duplicates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m320\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mPQ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfound_duplicates\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnumber_of_duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "# treshold t\n",
    "lsh_pairs = set()\n",
    "threshold = (1 / b) ** (1 / r)\n",
    "for tuple in candidate_pairs:\n",
    "    if jaccardSim(df[tuple[0]], df[tuple[1]]) > threshold:\n",
    "        lsh_pairs.add((tuple[0], tuple[1]))\n",
    "#print(lsh_pairs)\n",
    "print(len(lsh_pairs))\n",
    "\n",
    "\n",
    "# checking the number of real duplicates foun\n",
    "classification_df = pd.DataFrame(columns=['candidates', 'duplicate label'])\n",
    "for lshpair in lsh_pairs:\n",
    "    array1 = df[lshpair[0]].to_list()\n",
    "    array2 = df[lshpair[1]].to_list()\n",
    "    array = array1 + array2\n",
    "    if validation_df['model ID'][lshpair[0]] == validation_df['model ID'][lshpair[1]]:\n",
    "        classification_df = classification_df.append({'candidates': array, 'duplicate label': 1}, ignore_index=True)\n",
    "    else:\n",
    "        classification_df = classification_df.append({'candidates': array, 'duplicate label': 0}, ignore_index=True)\n",
    "classification_df.to_csv('class_df.csv')\n",
    "\n",
    "# Pair completness and Pair Quality\n",
    "found_duplicates = print(sum(classification_df['duplicate label']))\n",
    "number_of_duplicates = 399\n",
    "PQ = found_duplicates/number_of_duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a8ddf723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  0  1  2  3  4  5  6  7  8  ...  660  661  662  663  664  \\\n",
      "0               0  0  0  1  0  0  0  0  0  0  ...    0    0    0    0    0   \n",
      "1               1  0  0  1  0  1  0  0  0  0  ...    0    0    0    0    0   \n",
      "2               2  0  0  1  0  1  0  0  0  0  ...    0    0    0    0    0   \n",
      "3               3  0  0  1  0  1  0  0  0  0  ...    0    0    0    0    0   \n",
      "4               4  0  0  1  0  1  0  0  0  0  ...    0    0    0    0    0   \n",
      "...           ... .. .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...   \n",
      "24105       24105  0  0  1  0  0  0  0  0  0  ...    0    0    0    0    0   \n",
      "24106       24106  0  0  1  0  0  0  0  0  0  ...    0    0    0    0    0   \n",
      "24107       24107  0  0  1  0  1  0  0  0  0  ...    0    0    0    0    0   \n",
      "24108       24108  0  0  1  0  1  0  0  0  0  ...    0    0    0    0    0   \n",
      "24109       24109  0  0  1  0  0  0  0  0  0  ...    0    0    0    0    0   \n",
      "\n",
      "       665  666  667  668  669  \n",
      "0        0    0    0    0    0  \n",
      "1        0    0    0    0    0  \n",
      "2        0    0    0    0    0  \n",
      "3        0    0    0    0    0  \n",
      "4        0    0    0    0    0  \n",
      "...    ...  ...  ...  ...  ...  \n",
      "24105    0    0    0    0    0  \n",
      "24106    0    0    0    0    0  \n",
      "24107    0    0    0    0    0  \n",
      "24108    0    0    0    0    0  \n",
      "24109    0    0    0    0    0  \n",
      "\n",
      "[24110 rows x 671 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# X_try = pd.DataFrame(columns=range(670))\n",
    "# classi = pd.DataFrame(classification_df)\n",
    "# classi = classi.drop(['duplicate label'])\n",
    "# print(classi)\n",
    "# for index, lst in enumerate(classification_df.candidates):\n",
    "#         X_try[index] = lst\n",
    "#         X_try[lst(index)] = classi[index].loc[lst]\n",
    "Y = pd.Series(classification_df['duplicate label'].astype('int'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = pd.read_csv(\"X.csv\", sep=\",\")\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "#Calculate PC\n",
    "comparisons = nrow(X)\n",
    "Pair_completness = found_duplicates/comparisons\n",
    "\n",
    "predictions = []\n",
    "f1_score = []\n",
    "\n",
    "#Bootstrapping the Random Forest Algorithm\n",
    "for bs in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size=0.37)\n",
    "    ET = ExtraTreesClassifier(random_state=42, bootstrap=True).fit(X_train, Y_train)\n",
    "    ypred = ET.predict(X_test)\n",
    "    score = f1_score(Y_test, y_pred)\n",
    "    f1_score.append(score)\n",
    "\n",
    "finalprediction = np.mean(predictions)\n",
    "print(finalpredicton)\n",
    "\n",
    "\n",
    "\n",
    "print(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
